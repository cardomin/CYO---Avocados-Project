---
title: 'HarvardX: PH125.9x Data Science: Capstone - CYO Avocados Project'
author: "Carlos Dominguez Monferrer"
date: "September 4th, 2020"
output:
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\pagebreak

# **Executive summary**

The key idea is to create a system to predict prices of avocados in U.S. Avocado per capita consumption grew at 405.8% from 1990-1991 to 2016-2017, and the overall fruit category in the United States grew just 28.5% over that same time period. Rapid growth of U.S. demand for fresh avocados has increased the fruit’s prominence in retail sales and consumer diets. This growth is largely due to California producer and importer-funded research and promotion programs that have changed avocados image to that of a healthy superfood. Total California production has decreased slightly over time with the growth in consumption satisfied by imports, primarily from Mexico. U.S. consumers now enjoy year-round availability of avocados with more stable month-to-month prices than previously observed.

The purpose of this project is to know the influence of different variables such as total number of avocados sold, type of avocado (conventional or organic) or region on prices and predict prices of avocados in U.S. to avoid an inflation in a certain region and to help to find a city with cheap avocados.

The data that will be used has been downloaded from the Hass Avocado Board website in May of 2018 & compiled into a single CSV. More information at https://www.kaggle.com/neuromusic/avocado-prices?select=avocado.csv and https://hassavocadoboard.com/

```{r, include=FALSE}
# Packages that are needed to resolve the Avocados Project

library(tidyverse)
library(caret)
library(data.table)
library(lubridate)
library(ggplot2)
library(ggpubr)
library(MASS)

# Avocado Prices dataset
# https://www.kaggle.com/neuromusic/avocado-prices?select=avocado.csv

av <- tempfile()
download.file("https://www.kaggle.com/neuromusic/avocado-prices/download", av)

avocado_csv <- read.csv("C:/Users/cdomi/Downloads/avocado.csv")

# Due to R 3.6.3 is used, we add sample.kind argument to set.seed function.
set.seed(1, sample.kind="Rounding")

# Development set will be 80% of Avocados data. Then, train and test sets will be 70% and 30% respectively of Development data.
# Validation set will be 20% of Avocados data
# Note that these percentages are based on the paper below. It is important to know that depend on the size of the database
# Shahin, M. A., Maier, H. R., and Jaksa, M. B. (2004). "Data division for developing neural networks applied to geotechnical engineering." Journal of Computing in Civil Engineering,ASCE, 18(2), [105-114]

test_index <- createDataPartition(y = avocado_csv$AveragePrice, times = 1, p = 0.8, list = FALSE)

Development <- avocado_csv[test_index,]
Validation <- avocado_csv[-test_index,]
```

# **Methods/Analysis**

Before creating and optimizing the algorithm, an analysis of Avocados dataset is needed to know the type of data we will work with and the influence of the different variables on average price. The Average Price (of avocados) in the table reflects a per unit (per avocado) cost.

In order to make the code easier to understand, the Analysis section has been divided in two parts:

Data exploration:

+	Number of rows and columns
+	Name of the variables
+	Summary of Development and Validations sets
+	Number of different types, years and regions in both datasets

Data cleaning and Influence of variables on average price:

+	Convert Date variable (factor) to a date. 
+	Relation between Date and average price.
+	Relation between the type of avocado (conventional or organic) and average price.
+ Relation between the city or region of the observation (region variable) and average price.
+ Relation between total number of avocados sold (Total Volume) and average price.

Other variables like Product Lookup codes (PLU’s) (X4046, 4225, 4770) and bags have not been used in this project.

**Note**: Development and Validation sets will be 80% and 20% respectively of Avocados data. Train and test sets will be 70% and 30% respectively of Development data. These percentages are based on the paper *Shahin, M. A., Maier, H. R., and Jaksa, M. B. (2004). "Data division for developing neural networks applied to geotechnical engineering." Journal of Computing in Civil Engineering,ASCE, 18(2), [105-114]*. However, it is important to know that these values depend on the size of the database.

## Data exploration

### Number of rows & columns

+ Development dataset

Number of rows
```{r, echo=FALSE}
nrow(Development)
```

Number of columns
```{r, echo=FALSE}
ncol(Development) 
```
       
+ Validation dataset

Number of rows
```{r, echo=FALSE}
nrow(Validation)
```

Number of columns
```{r, echo=FALSE}
ncol(Validation) 
```

### Name of the variables 

There are 14 different variables in both datasets:
  
```{r, echo=FALSE}

colnames(Development) 
```

### Summary stadistics
  
+ Development dataset
  
```{r, echo=FALSE}

summary(Development)
```

+ Validation dataset

```{r, echo=FALSE}

summary(Validation)
```

### How many different types, years and regions are in both datasets

+ Development dataset

Different types

```{r, echo=FALSE}

n_distinct(Development$type)
```

Different years

```{r, echo=FALSE}

n_distinct(Development$year) 
```

Different regions

```{r, echo=FALSE}

n_distinct(Development$region) 
```

+ Validation dataset

Different types

```{r, echo=FALSE}

n_distinct(Validation$type)
```

Different years

```{r, echo=FALSE}

n_distinct(Validation$year) 
```

Different regions

```{r, echo=FALSE}

n_distinct(Validation$region) 
```


## Data cleaning and Influence of variables on rating

### Date & Average Price

In order to do a complete analysis of the influence of Date on average price, 2 graphs are plotted:

+ Date rounded to week.
+ Date rounded to month.

```{r, echo=FALSE, warning=FALSE, message=FALSE}

# Firstable, we are converting Date variable (that is a factor class) to a date.

# Then, we are rounding it by week (date_week) and month (date_month)  to see the relationship between these new variables and Average Prices

Development <- Development %>% mutate(Datetime = as_datetime(Date)) %>% mutate(date_week = round_date(Datetime, unit = "week"),date_month = round_date(Datetime, unit = "month")) 

Date_week <- Development %>% group_by(date_week) %>% summarize(AvPrice = mean(AveragePrice)) %>% ggplot(aes(date_week,AvPrice)) + geom_point() + geom_smooth() + ggtitle("Date rounded to week & Average Price") + labs(x = "Date rounded to week", y = "Average Price")
Date_week

Date_month <- Development %>% group_by(date_month) %>% summarize(AvPrice = mean(AveragePrice)) %>% ggplot(aes(date_month,AvPrice)) + geom_point() + geom_smooth() + ggtitle("Date rounded to month & Average Price") + labs(x = "Date rounded to month", y = "Average Price")
Date_month
```

**Conclusion 1.-:** There is strong evidence of a date effect on average price.

### Type & Average Price

Relation between the type of avocado (conventional or organic) and Average Price.

```{r, echo=FALSE, warning=FALSE, message=FALSE}


Development %>% group_by(type) %>% summarize(AvPrice = mean(AveragePrice)) %>% ggplot(aes(reorder(type,AvPrice),AvPrice)) + geom_bar(stat="identity", width=0.1, color = "black", fill = "aquamarine2") + labs(x = "Type", y = "Average Price") +
  ggtitle("Type & Average Price")
```

**Conclusion 2.-:** There is strong evidence of a type effect on average price.

### Region & Average Price

Relation between the city or region of the observation (region variable) and Average Price.

```{r, echo=FALSE,fig.height = 8, warning=FALSE, message=FALSE}

Development %>% group_by(region) %>% summarize(AvPrice = mean(AveragePrice)) %>% ggplot(aes(reorder(region,AvPrice),AvPrice, fill = AvPrice)) + geom_bar(stat="identity", width=0.5) + coord_flip() + scale_fill_distiller(palette = "YlOrRd") + labs(x = "Region", y = "Average Price") +
  ggtitle("Region & Average Price")
```

**Conclusion 3.-:** There is strong evidence of a region effect on average price. Hartford–Springfield is the most expensive region with an average price of 1.8 dollars per unit and Houston is the cheapest city with an average price of 1.2 dollars per unit. A difference of 66%!

### Total volume & Average Price

Relation between total number of avocados sold (Total Volume) and Average Price.

```{r, echo=FALSE, warning=FALSE, message=FALSE}


Development %>% group_by(AveragePrice) %>% summarize(T.Volume = mean(Total.Volume)) %>% ggplot(aes(T.Volume, AveragePrice)) + geom_point() + geom_smooth() + ggtitle("Total Volume & Average Price") + labs(x = "Total Volume", y = "Average Price") 
```

**Conclusion 4.-:** There is strong evidence of a Total Volume effect on average price.

\pagebreak

# **Results**

## **Training process**

To train our algotithm, we will calculate first RMSE without regularization technique.

```{r, echo=FALSE,warning=FALSE, message=FALSE}

# Due to R 3.6.3 is used, we add sample.kind argument to set.seed function.
set.seed(2020,sample.kind = "Rounding")
options(digits = 5)

# Train set will be 70% of Development data
# Test set will be 30% of Development data

Development_test_index <- createDataPartition(Development$AveragePrice,times = 1, p = 0.3, list = FALSE)

train <- Development[-Development_test_index,]
test <- Development[Development_test_index,]
```

### Just the average

```{r, echo=FALSE,warning=FALSE, message=FALSE}

mu_hat <- mean(train$AveragePrice)

naive_rmse <- RMSE(test$AveragePrice,mu_hat)

options(pillar.sigfig = 5)
rmse_results <- tibble(Model = "Just the average", RMSE = naive_rmse)
rmse_results
```

### Date effect

```{r, echo=FALSE,warning=FALSE, message=FALSE}

date_avgs <- train%>%
  group_by(Date) %>%
  summarize(b_d = mean(AveragePrice-mu_hat))

predicted_average <- mu_hat + test %>%
  left_join(date_avgs, by='Date') %>%
  pull(b_d)
Date_model <- RMSE(predicted_average, test$AveragePrice,na.rm=TRUE)
rmse_results <- bind_rows(rmse_results,
                          data_frame(Model="Date Effect",  
                                     RMSE =Date_model))
rmse_results 
```

### Type effect

```{r, echo=FALSE,warning=FALSE, message=FALSE}

type_avgs <- train %>%
  group_by(type) %>%
  summarize(b_t = mean(AveragePrice-mu_hat))

predicted_average <- mu_hat + test %>%
  left_join(type_avgs, by='type') %>%
  pull(b_t)
type_model <- RMSE(predicted_average, test$AveragePrice,na.rm=TRUE)
rmse_results <- bind_rows(rmse_results,
                          data_frame(Model="Type Effect",  
                                     RMSE =type_model))
rmse_results 
```

### Region effect

```{r, echo=FALSE,warning=FALSE, message=FALSE}

region_avgs <- train %>%
  group_by(region) %>%
  summarize(b_r = mean(AveragePrice-mu_hat))

predicted_average <- mu_hat + test %>%
  left_join(region_avgs, by='region') %>%
  pull(b_r)
region_model <- RMSE(predicted_average, test$AveragePrice,na.rm=TRUE)
rmse_results <- bind_rows(rmse_results,
                          data_frame(Model="Region Effect",  
                                     RMSE =region_model))
rmse_results 
```

### Total Volume effect

```{r, echo=FALSE,warning=FALSE, message=FALSE}

volume_avgs <- train %>%
  group_by(Total.Volume) %>%
  summarize(b_v = mean(AveragePrice-mu_hat))

predicted_average <- mu_hat + test %>%
  left_join(volume_avgs, by='Total.Volume') %>%
  pull(b_v)
volume_model <- RMSE(predicted_average, test$AveragePrice,na.rm=TRUE)
rmse_results <- bind_rows(rmse_results,
                          data_frame(Model="Total Volume Effect",  
                                     RMSE =volume_model))
rmse_results 
```

Due to Type and Region variables got the smallest RMSE values, we will combine them in order to check if we can reduce the Root Mean Squared Error.

### Type + Region effect

```{r, echo=FALSE,warning=FALSE, message=FALSE}

type_avgs <- train %>%
  left_join(region_avgs, by='region') %>%
  group_by(type) %>%
  summarize(b_t = mean(AveragePrice - mu_hat - b_r))

predicted_ratings <- test %>%
  left_join(region_avgs, by='region') %>%
  left_join(type_avgs, by='type') %>%
  mutate(pred = mu_hat + b_t + b_r) %>%
  pull(pred)

Type_plus_Region_model <- RMSE(predicted_ratings, test$AveragePrice,na.rm=TRUE)
rmse_results <- bind_rows(rmse_results,
                          data_frame(Model="Type + Region Effects",  
                                     RMSE =Type_plus_Region_model))
rmse_results 
```

Know, we will calculate RMSE with regularization technique.

### Regularization with Date effect

```{r, echo=FALSE,warning=FALSE, message=FALSE}

lambdas_1 <- seq(0, 10, 0.1)
rmses_1 <- sapply(lambdas_1, function(l){
  mu <- mean(train$AveragePrice)
  b_d <- train %>%
    group_by(Date) %>%
    summarize(b_d = sum(AveragePrice - mu)/(n()+l))
  
  predicted_ratings <-
    test %>%
    left_join(b_d, by = "Date") %>%
    mutate(pred = mu + b_d) %>%
    pull(pred)
  
  return(RMSE(predicted_ratings, test$AveragePrice,na.rm = TRUE))
})
```

Lambda value:

```{r, echo=FALSE,warning=FALSE, message=FALSE}

lambdas_1[which.min(rmses_1)]
qplot(lambdas_1,rmses_1,main = "Lambda vs RMSE | Regularization with Date effect",xlab = "Lambda",ylab = "RMSE")
Reg_Date_model <- min(rmses_1)
rmse_results <- bind_rows(rmse_results,
                          data_frame(Model="Regularized Date Effect",  
                                     RMSE =Reg_Date_model))
rmse_results 
```

### Regularization with Type effect

```{r, echo=FALSE,warning=FALSE, message=FALSE}

lambdas_2 <- seq(60, 75, 0.1)
rmses_2 <- sapply(lambdas_2, function(l){
  mu <- mean(train$AveragePrice)
  b_t <- train %>%
    group_by(type) %>%
    summarize(b_t = sum(AveragePrice - mu)/(n()+l))
  
  predicted_ratings <-
    test %>%
    left_join(b_t, by = "type") %>%
    mutate(pred = mu + b_t) %>%
    pull(pred)
  
  return(RMSE(predicted_ratings, test$AveragePrice,na.rm = TRUE))
})
```

Lambda value:

```{r, echo=FALSE,warning=FALSE, message=FALSE}

lambdas_2[which.min(rmses_2)]
qplot(lambdas_2,rmses_2,main = "Lambda vs RMSE | Regularization with Type effect",xlab = "Lambda",ylab = "RMSE")
Reg_Type_model <- min(rmses_2)
rmse_results <- bind_rows(rmse_results,
                          data_frame(Model="Regularized Type Effect",  
                                     RMSE =Reg_Type_model))
rmse_results 
```

### Regularization with Region effect

```{r, echo=FALSE,warning=FALSE, message=FALSE}

lambdas_3 <- seq(15, 25, 0.1)
rmses_3 <- sapply(lambdas_3, function(l){
  mu <- mean(train$AveragePrice)
  b_r <- train %>%
    group_by(region) %>%
    summarize(b_r = sum(AveragePrice - mu)/(n()+l))
  
  predicted_ratings <-
    test %>%
    left_join(b_r, by = "region") %>%
    mutate(pred = mu + b_r) %>%
    pull(pred)
  
  return(RMSE(predicted_ratings, test$AveragePrice,na.rm = TRUE))
})
```

Lambda value:

```{r, echo=FALSE,warning=FALSE, message=FALSE}

lambdas_3[which.min(rmses_3)]
qplot(lambdas_3,rmses_3,main = "Lambda vs RMSE | Regularization with Region effect",xlab = "Lambda",ylab = "RMSE")
Reg_Region_model <- min(rmses_3)
rmse_results <- bind_rows(rmse_results,
                          data_frame(Model="Regularized Region Effect",  
                                     RMSE =Reg_Region_model))
rmse_results
```

### Regularization with Total Volume effect

```{r, echo=FALSE,warning=FALSE, message=FALSE}

lambdas_4 <- seq(0, 2.5, 0.05)
rmses_4 <- sapply(lambdas_4, function(l){
  mu <- mean(train$AveragePrice)
  b_v <- train %>%
    group_by(Total.Volume) %>%
    summarize(b_v = sum(AveragePrice - mu)/(n()+l))
  
  predicted_ratings <-
    test %>%
    left_join(b_v, by = "Total.Volume") %>%
    mutate(pred = mu + b_v) %>%
    pull(pred)
  
  return(RMSE(predicted_ratings, test$AveragePrice,na.rm = TRUE))
})
```

Lambda value:

```{r, echo=FALSE,warning=FALSE, message=FALSE}

lambdas_4[which.min(rmses_4)]
qplot(lambdas_4,rmses_4,main = "Lambda vs RMSE | Regularization with Total Volume effect",xlab = "Lambda",ylab = "RMSE")
Reg_Volume_model <- min(rmses_4)
rmse_results <- bind_rows(rmse_results,
                          data_frame(Model="Regularized Total Volume Effect",  
                                     RMSE =Reg_Volume_model))
rmse_results
```

Due to Type and Region variables got the smallest RMSE values, we will combine them in order to check if we can reduce the Root Mean Squared Error with regularization technique.

### Regularization with Type + Region effect

```{r, echo=FALSE,warning=FALSE, message=FALSE}

lambdas_5 <- seq(2.5, 15, 0.1)
rmses_5 <- sapply(lambdas_5, function(l){
  mu <- mean(train$AveragePrice)
  b_r <- train %>%
    group_by(region) %>%
    summarize(b_r = sum(AveragePrice - mu)/(n()+l))
  
  b_t <- train %>%
    left_join(b_r, by="region") %>%
    group_by(type) %>%
    summarize(b_t = sum(AveragePrice - b_r - mu)/(n()+l))
  
  predicted_ratings <-
    test %>%
    left_join(b_r, by = "region") %>%
    left_join(b_t, by = "type") %>%
    mutate(pred = mu + b_r + b_t) %>%
    pull(pred)
  
  return(RMSE(predicted_ratings, test$AveragePrice,na.rm = TRUE))
})
```

Lambda value:

```{r, echo=FALSE,warning=FALSE, message=FALSE}

lambdas_5[which.min(rmses_5)]

qplot(lambdas_5,rmses_5,main = "Lambda vs RMSE | Regularization with Type + Region effect",xlab = "Lambda",ylab = "RMSE")
lambda <- lambdas_5[which.min(rmses_5)]
Reg_Type_plus_Region_model <- min(rmses_5)
rmse_results <- bind_rows(rmse_results,
                          data_frame(Model="Regularized Type + Region Effects",  
                                     RMSE =Reg_Type_plus_Region_model))
rmse_results 
```

For this project, we have to apply machine learning techniques that go beyond standard linear regression so glm, RandomForest and knn techniques are also tested to try to reduce RMSE value. Other techniques such as lda, qda or Naive Bayes have not been finally used because they have generated errors whose solution has not been found.

### Generalized Linear Models (Glm)

```{r, echo=FALSE,warning=FALSE, message=FALSE}

train_glm <- train(AveragePrice ~ Date + Total.Volume + type + region, method = "glm", data = train)
y_hat_glm <- predict(train_glm, test, type = "raw")

glm_RMSE <- RMSE(test$AveragePrice,y_hat_glm)
rmse_results <- bind_rows(rmse_results,
                          data_frame(Model="Glm",  
                                     RMSE =glm_RMSE))
rmse_results 
```

### Random Forest

Because with random forest the fitting is the slowest part of the procedure rather than the predicting (as with kNN), we will use only three ntrees values: 10, 30 and 50. It is recommend it to use more than 100 trees but the time of computation is too hight.

#### 10 trees

```{r, echo=FALSE,fig.align = "center",warning=FALSE, message=FALSE}

train_rf_10 <- train(AveragePrice ~ Date + Total.Volume + type + region, method = "rf", data = train, ntree = 10,
                   tuneGrid = data.frame(mtry = 15))

y_hat_rf_10 <- predict(train_rf_10, test, type = "raw")

rf_10_RMSE <- RMSE(test$AveragePrice,y_hat_rf_10)
rmse_results <- bind_rows(rmse_results,
                          data_frame(Model="Random Forest - 10 trees",  
                                     RMSE =rf_10_RMSE))
rmse_results 

plot(train_rf_10$finalModel,main = "Trees vs Error | Random Forest - 10 trees")

```

#### 30 trees

```{r, echo=FALSE,fig.align = "center", warning=FALSE, message=FALSE}

train_rf_30 <- train(AveragePrice ~ Date + Total.Volume + type + region, method = "rf", data = train, ntree = 30,
                  tuneGrid = data.frame(mtry = 15))

y_hat_rf_30 <- predict(train_rf_30, test, type = "raw")

rf_30_RMSE <- RMSE(test$AveragePrice,y_hat_rf_30)
rmse_results <- bind_rows(rmse_results,
                          data_frame(Model="Random Forest - 30 trees",  
                                     RMSE =rf_30_RMSE))
rmse_results

plot(train_rf_30$finalModel,main = "Trees vs Error | Random Forest - 30 trees")
```

#### 50 trees

```{r, echo=FALSE,fig.align = "center", warning=FALSE, message=FALSE}

train_rf_50 <- train(AveragePrice ~ Date + Total.Volume + type + region, method = "rf", data = train, ntree = 50,
                     tuneGrid = data.frame(mtry = 15))

y_hat_rf_50 <- predict(train_rf_50, test, type = "raw")

rf_50_RMSE <- RMSE(test$AveragePrice,y_hat_rf_50)
rmse_results <- bind_rows(rmse_results,
                          data_frame(Model="Random Forest - 50 trees",  
                                     RMSE =rf_50_RMSE))
rmse_results

plot(train_rf_50$finalModel,main = "Trees vs Error | Random Forest - 50 trees")
```

### Knn

As Random Forest model, in Knn the fitting is the slowest part of the procedure rather than the predicting. We will use only three-fold cross validation: 200, 250 and 300. Other values have been tested (1,7,50,100, etc) but the trend of the error curve was decreasing for higher values of k.

```{r, echo=FALSE,warning=FALSE, message=FALSE}

train_knn_1 <- train(AveragePrice ~ Date + Total.Volume + type + region, method = "knn", data = train,
                     tuneGrid = data.frame(k = seq(200,300,50)))

seq_k_1 <- plot(train_knn_1,main = "Neighbors vs RMSE (Bootstrap)")
seq_k_1
y_hat_knn_1 <- predict(train_knn_1, test, type = "raw")

knn_1_RMSE <- RMSE(test$AveragePrice,y_hat_knn_1)
rmse_results <- bind_rows(rmse_results,
                          data_frame(Model="Knn",  
                                     RMSE =knn_1_RMSE))
rmse_results 
```

\pagebreak

Analyzing the results, we notice that Random Forest with 50 trees model give us the smallest RMSE.

```{r, echo=FALSE,warning=FALSE, message=FALSE}

Results <- as.data.frame(rmse_results)
Results %>% arrange(RMSE)
```

## **Validations process**

```{r, echo=FALSE,warning=FALSE, message=FALSE}

rf_val <- train(AveragePrice ~ Date + Total.Volume + type + region, method = "rf", data = Development, ntree = 50,
                     tuneGrid = data.frame(mtry = 15))

plot(rf_val$finalModel,main = "Trees vs Error | Random Forest - 50 trees")

y_hat_rf_val <- predict(rf_val, Validation, type = "raw")
```

**Validation Root Mean Squared Error**

```{r, echo=FALSE,warning=FALSE, message=FALSE}

rf_val_RMSE <- RMSE(y_hat_rf_val,Validation$AveragePrice)
rf_val_RMSE
```

This RMSE value seems reasonable to achieve our objetive: to avoid an inflation in a certain region and to help to find a city with cheap avocados. 


\pagebreak

# **Conclusion**

The Methods/Analysis section has been necessary to know the type of data we were going to work with. 

With the analysis of the influence of variables on average price, we have seen that Type and Region were the most important variables. However, other variables such as the date of observation or year were also important.

In the beginning, RMSEs with basic models, like Just the Average, have been obtained. Then, regularization techniques have been used in order to reduce de Root Mean Squared Error but the results were not very good:

+ Type + Region Effects, RMSE = 0.27161
+ Regularized Type + Region Effects, RMSE =  0.27148

For this project, we have to apply machine learning techniques that go beyond standard linear regression so glm, RandomForest and knn techniques are also tested to try to reduce RMSE value. Other techniques such as lda, qda or Naive Bayes have not been finally used because they have generated errors whose solution has not been found.

It has been concluded that Random Forest with 50 trees has been optimal for the lower RSME value. However, because with this technique the fitting is the slowest part of the procedure rather than the predicting, only three ntrees values have been tested. Other biggers ntrees values could have been used to get lower RMSE but the time of computation would be too hight.

# **Appendix - Enviroment**

```{r, echo=FALSE,warning=FALSE, message=FALSE}
print("Operating System:")
version
```


